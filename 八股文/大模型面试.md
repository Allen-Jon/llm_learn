# 大语言模型（LLM）知识体系大纲

本文档旨在构建一个系统化、由浅入深、内容明确的大语言模型知识框架，覆盖从底层原理到上层应用的全链路。

### **第一部分：神经网络与深度学习基础**

- **1.1 机器学习与神经网络基本概念**
  - 1.1.1 机器学习、深度学习、神经网络之间的关系是什么？
  - 1.1.2 典型的神经网络结构包含哪些部分（输入层、隐藏层、输出层）？
  - 1.1.3 什么是激活函数（如 Sigmoid, ReLU）？它们的作用是什么？
  - 1.1.4 损失函数（Loss Function）和优化器（Optimizer，如梯度下降）是如何工作的？
  - 1.1.5 训练、验证、测试集的作用与划分。
- **1.2 经典神经网络模型**
  - 1.2.1 **循环神经网络 (RNN)**：其基本结构、为何能处理序列数据？存在哪些问题（如梯度消失/爆炸）？
  - 1.2.2 **长短期记忆网络 (LSTM)**：它如何通过门控机制（输入门、遗忘门、输出门）解决 RNN 的问题？
  - 1.2.3 **卷积神经网络 (CNN)**：其核心组件（卷积层、池化层）是什么？主要应用于哪些领域？

### **第二部分：Transformer 模型核心架构**

- **2.1 Transformer 整体架构**
  - 2.1.1 Transformer 的整体架构是怎样的（编码器-解码器）？
  - 2.1.2 它与 RNN/LSTM 相比，最大的优势是什么（并行化处理）？
- **2.2 注意力机制 (Attention Mechanism)**
  - 2.2.1 **自注意力机制 (Self-Attention)** 是如何工作的？Q, K, V 向量分别代表什么？
  - 2.2.2 **多头注意力 (Multi-Head Attention)** 的作用是什么？为什么不只用一个头？
  - 2.2.3 什么是**缩放点积注意力 (Scaled Dot-Product Attention)**？为什么要进行缩放？
- **2.3 Transformer 关键组件**
  - 2.3.1 **位置编码 (Positional Encoding)** 的必要性？它是如何实现的？
  - 2.3.2 **前馈神经网络 (Feed-Forward Network)** 子层的作用和结构是怎样的？
  - 2.3.3 **残差连接 (Residual Connections)** 与**层归一化 (Layer Normalization)** 在模型中起到了什么关键作用？

### **第三部分：主流 LLM 模型谱系解析**

- **3.1 仅编码器模型 (Encoder-only)**
  - 3.1.1 **BERT**: 核心思想（MLM, NSP）、架构特点及其在 NLP 领域的贡献是什么？
- **3.2 仅解码器模型 (Decoder-only)**
  - 3.2.1 **GPT 系列**: 核心思想（自回归）、架构特点及其在文本生成领域的应用。
- **3.3 编码器-解码器模型 (Encoder-Decoder)**
  - 3.3.1 **T5**: 其“文本到文本”的统一框架有何特点？
- **3.4 模型改进与对比**
  - 3.4.1 **RoBERTa** 这类模型对 BERT 做了哪些关键改进？
  - 3.4.2 Encoder-only, Decoder-only, Encoder-Decoder 三种架构分别最适合哪些类型的任务？

### **第四部分：LLM 全生命周期：数据、训练与评估**

- **4.1 数据工程 (Data Engineering)**
  - 4.1.1 **数据预处理**: 包括哪些关键步骤（清洗、格式化、去噪等）？
  - 4.1.2 **分词 (Tokenization)**: 什么是分词？为什么它至关重要？
  - 4.1.3 **分词策略**: 对比基于词、字符和子词（BPE, WordPiece）的策略优缺点。中文分词有何特殊性？
  - 4.1.4 **词嵌入 (Embeddings)**: 什么是词嵌入？为何优于 One-hot 编码？静态嵌入（Word2Vec）与上下文感知嵌入（BERT/GPT）有何核心区别？
  - 4.1.5 **词汇表 (Vocabulary)**: 构建原则是什么？大小对模型性能和效率有何影响？
  - 4.1.6 **长文本处理**: 有哪些常见的分块（Chunking）策略？如何处理超长上下文？
- **4.2 训练与微调策略 (Training & Fine-tuning)**
  - 4.2.1 **全量微调 (Full Fine-tuning)**: 流程、优缺点是什么？
  - 4.2.2 **参数高效微调 (PEFT)**: 基本思想是什么？为何如此重要？
  - 4.2.3 **主流 PEFT 方法**: LoRA, Adapter Tuning, Prompt/Prefix Tuning 的核心原理与优缺点。
  - 4.2.4 **QLoRA**: 它相比 LoRA 在显存优化方面做了哪些改进？
- **4.3 对齐与强化学习 (Alignment & Reinforcement Learning)**
  - 4.3.1 **对齐 (Alignment)**: 什么是 LLM 的对齐问题？为何它至关重要？
  - 4.3.2 **指令微调 (SFT)**: 概念、目标和流程是怎样的？它在对齐中扮演什么角色？
  - 4.3.3 **基于人类反馈的强化学习 (RLHF)**: 其完整三阶段流程是怎样的？
  - 4.3.4 **奖励模型 (Reward Model)**: 如何训练？在 RLHF 中扮演什么角色？
  - 4.3.5 **PPO 算法**: 在 RLHF 中起什么作用？
  - 4.3.6 **直接偏好优化 (DPO)**: 它与 RLHF 的主要区别是什么？试图解决什么问题？
- **4.4 实践与监控 (Practice & Monitoring)**
  - 4.4.1 **策略选择**: 如何根据任务需求和资源选择合适的微调策略？
  - 4.4.2 **超参数调整**: 学习率、批大小、轮数等关键超参数如何影响微调效果？
  - 4.4.3 **性能监控**: 如何判断微调是否有效或过拟合？
  - 4.4.4 **灾难性遗忘**: 什么是灾难性遗忘？有哪些缓解策略？

### **第五部分：LLM 应用开发与生态**

- **5.1 提示工程 (Prompt Engineering)**
  - 5.1.1 什么是提示工程？它与微调的本质区别是什么？
  - 5.1.2 常见的提示策略有哪些（Few-shot, Chain-of-Thought 等）？
- **5.2 检索增强生成 (RAG)**
  - 5.2.1 RAG 的核心思想和典型架构是怎样的？
  - 5.2.2 它主要解决了 LLM 的哪些问题（知识陈旧、幻觉）？
  - 5.2.3 **向量数据库**: 在 RAG 中扮演什么角色？其基本原理是什么？
- **5.3 智能体 (Agents)**
  - 5.3.1 什么是 LLM Agent？其核心组件有哪些（规划、记忆、工具使用）？
  - 5.3.2 ReAct (Reason+Act) 等典型的 Agent 框架是如何工作的？
- **5.4 开发框架与工具**
  - 5.4.1 **LangChain / LlamaIndex**: 这类框架的核心价值是什么？提供了哪些核心功能？
  - 5.4.2 如何使用这些框架快速构建一个简单的 RAG 应用？

### **第六部分：LLM 的评估、挑战与前沿**

- **6.1 模型评估**
  - 6.1.1 有哪些常用的 LLM 评估基准（Benchmark）？
  - 6.1.2 如何评估模型的安全性、事实准确性和推理能力？
- **6.2 挑战与局限性**
  - 6.2.1 Transformer 架构的主要局限性（计算复杂度、上下文长度）。
  - 6.2.2 RLHF 流程存在哪些挑战（成本、主观性、对齐税）？
  - 6.2.3 LLM 的“幻觉”问题：成因与缓解方法。
- **6.3 前沿与展望**
  - 6.3.1 **多模态**: LLM 如何融合图像、音频等不同模态的信息？
  - 6.3.2 **模型编辑与持续学习**: 这些技术试图解决什么问题？
  - 6.3.3 **负责任的 AI (Responsible AI)**: 偏见、公平性、透明度等伦理问题。